server:
  port: 9092
  servlet:
    context-path: /
spring:
  application:
    name: feng-server
  mvc:
    pathmatch:
      matching-strategy: ANT_PATH_MATCHER
  kafka:
    bootstrap-servers: 10.134.1.24:9092,10.134.1.25:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      # 手动提交
      group-id: hy-otc
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        session.timeout.ms: 60000
    listener:
      log-container-config: false
      concurrency: 5
      # 手动提交
      ack-mode: manual
  redis:
    database: 0
    password: 123456
    sentinel:
      master: mymaster
      nodes:
        - 10.134.1.27:26379
        - 10.134.1.27:26479
        - 10.134.1.27:26579
    lettuce:
      pool:
        max-active: 1000
        max-idle: 50
        min-idle: 20
        max-wait: -1
  datasource:
    #1.JDBC
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://10.12.5.34:3306/saleorderdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=UTC&rewriteBatchedStatements=true
    username: root
    password: AGq/WUaS9ZVWWqVpRsydUTbDEq49Z/jlm6fZ1k/SXEzQSSdsBc0qyz/KmOCRZQpKdU3fLoAge19+j+5ihxoOFw==
    druid:
      connection-properties: config.decrypt=true;config.decrypt.key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAKrtZFTJxjL+ZNsRfPP0BUGtW5Qi00UbBCFxq08H49DLVcfLGkZ4pPXpnMTyZ/59H/bSLKmNuJMy0mf0i2W4Fp8CAwEAAQ==
      #2.连接池配置
      #初始化连接池的连接数量 大小，最小，最大
      initial-size: 10
      min-idle: 10
      max-active: 30
      #配置获取连接等待超时的时间
      max-wait: 60000
      #配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 30000
      validation-query: SELECT 1 FROM DUAL
      test-while-idle: true
      test-on-borrow: true
      test-on-return: false
      # 是否缓存preparedStatement，也就是PSCache  官方建议MySQL下建议关闭   个人建议如果想用SQL防火墙 建议打开
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      filter:
        config:
          enabled: true
        stat:
          # 开启监控sql
          enabled: true
          merge-sql: true
          # 显示并标注慢sql 默认当超过3秒显示
          log-slow-sql: true
          slow-sql-millis: 3000
        # 防SQL注入过滤
        wall:
          config:
          # 允许多条sql同时执行
          multi-statement-allow: true
      #3.基础监控配置
      web-stat-filter:
        enabled: true
        url-pattern: /*
        #设置不统计哪些URL
        exclusions: "*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*"
        session-stat-enable: true
        session-stat-max-count: 100
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
        reset-enable: true
        #设置监控页面的登录名和密码
        login-username: admin
        login-password: admin
        #允许访问的端口
        allow: 127.0.0.1
        #禁止访问的端口
        #deny: 192.168.1.100
dubbo:
  registry:
    address: zookeeper://10.134.1.25:3002
  protocol:
    name: dubbo
    port: 20890
    ##数据源配置
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: false
    auto-mapping-behavior: full
  #    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  mapper-locations: classpath*:mapper/**/*Mapper.xml
  global-config:
    # 逻辑删除配置
    db-config:
      # 删除前
      logic-not-delete-value: 0
      # 删除后
      logic-delete-value: 1
logging:
  level:
    com.example.mapper: trace
